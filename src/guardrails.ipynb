{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWG3JPB0jUJo"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "    nemoguardrails==0.4.0 \\\n",
        "    openai==0.27.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHQOTiTQjUJp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\") or \"your key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhZ9qy90jUJq"
      },
      "outputs": [],
      "source": [
        "yaml_content = \"\"\"\n",
        "models:\n",
        "- type: main\n",
        "  engine: openai\n",
        "  model: gpt-4o-mini\n",
        "\"\"\"\n",
        "colang_content = \"\"\"\n",
        "define niceties\n",
        "define user express greeting\n",
        "    \"hello\"\n",
        "    \"hi\"\n",
        "    \"what's up?\"\n",
        "\n",
        "define flow greeting\n",
        "    user express greeting\n",
        "    bot express greeting\n",
        "    bot ask how are you\n",
        "\n",
        "# define limits\n",
        "define user ask politics\n",
        "    \"what are your political beliefs?\"\n",
        "    \"thoughts on the president?\"\n",
        "    \"left wing\"\n",
        "    \"right wing\"\n",
        "\n",
        "define bot answer politics\n",
        "    \"I'm a shopping assistant, I don't like to talk of politics.\"\n",
        "\n",
        "define flow politics\n",
        "    user ask politics\n",
        "    bot answer politics\n",
        "    # bot offer help\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrKzVn4wjUJq"
      },
      "outputs": [],
      "source": [
        "from nemoguardrails import LLMRails, RailsConfig\n",
        "\n",
        "# initialize rails config\n",
        "config = RailsConfig.from_content(\n",
        "  \tyaml_content=yaml_content,\n",
        "    colang_content=colang_content\n",
        ")\n",
        "# create rails\n",
        "rails = LLMRails(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWj4C79H7wLO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdI13hg4jUJq"
      },
      "source": [
        "From here, we begin asking questions and interacting with our Guardrails protected LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htzi4K72jUJq",
        "outputId": "8615c158-9d06-4423-b454-d7489ddb9e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there! How can I help you?\n",
            "How are you doing today?\n"
          ]
        }
      ],
      "source": [
        "res = await rails.generate_async(prompt=\"Hey there!\")\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2qv5mEujUJq"
      },
      "source": [
        "\n",
        "\n",
        "Let's try asking a more political question:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-e24M6PjUJq",
        "outputId": "e8f5c8b4-4a1a-495f-f6a9-4d86864933c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm a shopping assistant, I don't like to talk of politics.\n",
            "However, I can help you with shopping related tasks. Is there anything I can help you with?\n"
          ]
        }
      ],
      "source": [
        "res = await rails.generate_async(prompt=\"what do you think of the president?\")\n",
        "print(res)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
